{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: create datasets that's compatible with 3 gb models\n",
    "\"\"\"\n",
    "X_xgb: Dense, Target Encoded, Statistical Text Features.\n",
    "X_lgb: Integer Encoded, SVD Text Features, Aggregate Features.\n",
    "X_cat: Raw Categoricals, Raw Text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(original_df, text_col='Description'):\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # --- COMMON PREPROCESSING ---\n",
    "    # Fill N/As for text\n",
    "    df[text_col] = df[text_col].fillna('none')\n",
    "    \n",
    "    # Basic Feature Engineering (Shared) based on v1\n",
    "    df['name_length'] = df['Name'].str.len().fillna(0)\n",
    "    df['desc_length'] = df[text_col].str.len().fillna(0)\n",
    "    df['is_mixed_breed'] = (df['Breed2'] != 0).astype(int)\n",
    "    df['num_colors'] = (df[['Color1', 'Color2', 'Color3']] != 0).sum(axis=1)\n",
    "    \n",
    "    cat_columns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', \n",
    "                   'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \n",
    "                   'Sterilized', 'Health', 'State', 'RescuerID']\n",
    "    \n",
    "    # Convert all categoricals to string first (safer for encoding)\n",
    "    for c in cat_columns:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].astype(str)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1. XGBOOST DATASET (Dense, Numerical)\n",
    "    # -------------------------------------\n",
    "    X_xgb = df.copy()\n",
    "    \n",
    "    # Label Encode Categoricals for XGBoost\n",
    "    # (Note: For production, you must fit LE on train and transform test. \n",
    "    #  Here we assume df is the full dataset or this is handled before split)\n",
    "    for c in cat_columns:\n",
    "        if c in X_xgb.columns:\n",
    "            lbl = LabelEncoder()\n",
    "            X_xgb[c] = lbl.fit_transform(X_xgb[c])\n",
    "            \n",
    "    # Drop raw text\n",
    "    X_xgb = X_xgb.drop(['Name', 'PetID', 'Description', 'AdoptionSpeed'], axis=1, errors='ignore')\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 2. LIGHTGBM DATASET (Integer Cats + SVD Text)\n",
    "    # ---------------------------------------------\n",
    "    X_lgb = df.copy()\n",
    "    \n",
    "    # Pandas Category Type for LightGBM (it handles them natively & optimally)\n",
    "    for c in cat_columns:\n",
    "        if c in X_lgb.columns:\n",
    "            X_lgb[c] = X_lgb[c].astype('category')\n",
    "            \n",
    "    # TF-IDF + SVD for Description\n",
    "    tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "    \n",
    "    text_vectors = tfidf.fit_transform(df[text_col])\n",
    "    svd_vectors = svd.fit_transform(text_vectors)\n",
    "    \n",
    "    svd_df = pd.DataFrame(svd_vectors, columns=[f'svd_{i}' for i in range(10)])\n",
    "    \n",
    "    # Reset index to allow concat\n",
    "    X_lgb = X_lgb.reset_index(drop=True)\n",
    "    X_lgb = pd.concat([X_lgb, svd_df], axis=1)\n",
    "    \n",
    "    # Drop raw text\n",
    "    X_lgb = X_lgb.drop(['Name', 'PetID', 'Description', 'AdoptionSpeed'], axis=1, errors='ignore')\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3. CATBOOST DATASET (Raw Text & Strings)\n",
    "    # ----------------------------------------\n",
    "    \n",
    "    X_cat = df.copy()\n",
    "    \n",
    "    # CatBoost wants raw strings for categorical features (fill NaNs with \"Missing\")\n",
    "    for c in cat_columns:\n",
    "        if c in X_cat.columns:\n",
    "            X_cat[c] = X_cat[c].fillna(\"Missing\")\n",
    "    \n",
    "    # Define which columns are text/categorical for later use in model.fit()\n",
    "    # (CatBoost needs raw text columns to be kept)\n",
    "    X_cat = X_cat.drop(['Name', 'PetID', 'AdoptionSpeed'], axis=1, errors='ignore')\n",
    "    # Note: Keep 'Description' for CatBoost's text_features support\n",
    "\n",
    "    return X_xgb, X_lgb, X_cat\n",
    "\n",
    "# Usage Example:\n",
    "# 1. Combine Train/Test temporarily for consistent encoding (or fit/transform separately carefully)\n",
    "# all_data = pd.concat([pet_df, test_df], sort=False).reset_index(drop=True)\n",
    "# X_xgb_all, X_lgb_all, X_cat_all = create_datasets(all_data)\n",
    "\n",
    "# 2. Split back logic (simplified)\n",
    "# train_len = len(pet_df)\n",
    "# X_train_xgb = X_xgb_all[:train_len]\n",
    "# X_test_xgb = X_xgb_all[train_len:]\n",
    "# Same for lgb and cat..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
