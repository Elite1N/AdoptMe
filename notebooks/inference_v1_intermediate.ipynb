{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ae35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For handling module in diff dir\n",
    "import sys\n",
    "import os \n",
    "\n",
    "# Config\n",
    "TEST_DATA_PATH = '../data/test/test.csv'\n",
    "IMAGE_DIR = '../data/test_images/'\n",
    "OUTPUT_PATH = '../submission_v1.csv'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_DIR = '../data'\n",
    "MODELS_DIR = '../models/v1_stratify'\n",
    "IMG_DIR = os.path.join(DATA_DIR, 'train_images') \n",
    "\n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652f0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DEFINITIONS\n",
    "\n",
    "# 1. Text Model (Code from k4)\n",
    "class TransformerPetClassifier(nn.Module):\n",
    "    \"\"\"Transformer-based classifier for pet adoption speed prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='bert-base-uncased', num_classes=5, dropout=0.3):\n",
    "        super(TransformerPetClassifier, self).__init__()\n",
    "        \n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Get hidden size from transformer config\n",
    "        hidden_size = self.transformer.config.hidden_size\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, return_features=False):\n",
    "        # Get transformer outputs\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        if return_features:\n",
    "            # Pass through the first part of classification head (up to 128 dim)\n",
    "            x = self.classifier[0](pooled_output) # Linear 256\n",
    "            x = self.classifier[1](x) # ReLU\n",
    "            x = self.classifier[2](x) # Dropout\n",
    "            x = self.classifier[3](x) # Linear 128\n",
    "            return x # Return the 128-dim embedding\n",
    "        \n",
    "        return self.classifier(pooled_output)\n",
    "\n",
    "# 2. Image Model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.fc = nn.Linear(self.resnet.fc.in_features, 5) # Save the Fully connected layer seperatedly for full prediction\n",
    "        self.resnet.fc = nn.Identity() # Remove the original head\n",
    "        \n",
    "    def forward(self, x, return_features=False): \n",
    "        features = self.resnet(x) # 2048-dim embedding\n",
    "        if return_features:\n",
    "            return features\n",
    "        return self.fc(features)\n",
    "\n",
    "# 3. Tabular Model\n",
    "# no need to define xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85145e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CLASS\n",
    "class EnsembleDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, tokenizer, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # 1. Image Processing\n",
    "        img_path = os.path.join(self.img_dir, f\"{row['PetID']}-1.jpg\") \n",
    "        image = Image.new('RGB', (224, 224), (0, 0, 0)) \n",
    "        if os.path.exists(img_path):\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            except:\n",
    "                pass \n",
    "        if self.transform: image = self.transform(image)\n",
    "\n",
    "        # 2. Text Processing\n",
    "        desc = str(row['Description']) if pd.notna(row['Description']) else \"no description\"\n",
    "        encoding = self.tokenizer(\n",
    "            desc, max_length=64, padding='max_length', truncation=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe912386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_table(tabular_df):\n",
    "    # Namelength\n",
    "    tabular_df[\"name_length\"] = tabular_df['Name'].str.len().fillna(0)\n",
    "    \n",
    "    # Description length\n",
    "    tabular_df['description_length'] = tabular_df['Description'].str.len().fillna(0)\n",
    "    \n",
    "    \n",
    "    # Is Mixed Breed? (Breed2 is not 0)\n",
    "    tabular_df['is_mixed_breed'] = (tabular_df['Breed2'] != 0).astype(int)\n",
    "    \n",
    "    # Number of Colors (Count non-zero color columns)\n",
    "    tabular_df['num_colors'] = (tabular_df[['Color1', 'Color2', 'Color3']] != 0).sum(axis=1)\n",
    "    \n",
    "    # Is Free? (Fee is 0)\n",
    "    tabular_df['is_free'] = (tabular_df['Fee'] == 0).astype(int)\n",
    "\n",
    "    # Fee per Pet (Normizalized for litters)\n",
    "    tabular_df['fee_per_pet'] = tabular_df['Fee'] / tabular_df['Quantity'].replace(0, 1)\n",
    "\n",
    "    # Total Media (Engagement proxy)\n",
    "    tabular_df['total_media'] = tabular_df['PhotoAmt'] + tabular_df['VideoAmt']\n",
    "\n",
    "    # Health Issue Flag (Health > 1 implies injury or condition)\n",
    "    tabular_df['has_health_issue'] = (tabular_df['Health'] > 1).astype(int)\n",
    "    # --------------------\n",
    "    \n",
    "    # Encode state/breed as categories\n",
    "    # ADDED 'Type' to this list\n",
    "    cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', \n",
    "                    'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \n",
    "                    'Sterilized', 'Health', 'State']\n",
    "    for col in cat_cols:\n",
    "        if col in tabular_df.columns:\n",
    "            tabular_df[col] = tabular_df[col].astype('category')\n",
    "    return tabular_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff685371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_features(df, img_dir=IMG_DIR):\n",
    "    print(f\"Generating features for {len(df)} samples...\")\n",
    "    \n",
    "    # 1. XGBoost Inference\n",
    "    print(\"Loading XGBoost...\")\n",
    "    xgb_model = joblib.load(os.path.join(MODELS_DIR, 'xgb_stratify_optuna.pkl'))\n",
    "    \n",
    "    # Preprocess Tabular (Manual replication of src/tabular_model.py logic if not exposed as static method)\n",
    "    # Ideally: from src.tabular_model import TabularModel; TabularModel.preprocess(df)\n",
    "    \n",
    "    df_tab = featurize_table(df)\n",
    "    \n",
    "    drop_cols = ['Name', 'PetID', 'RescuerID', 'Description', 'AdoptionSpeed']\n",
    "    df_tab = df_tab.drop([c for c in drop_cols if c in df_tab.columns], axis=1)\n",
    "    \n",
    "    \n",
    "    xgb_probs = xgb_model.predict_proba(df_tab) # Shape (N, 5)\n",
    "\n",
    "    # 2. Load PyTorch Models\n",
    "    print(\"Loading DL Models...\")\n",
    "    # Image\n",
    "    img_model = ResNet().to(DEVICE)\n",
    "    img_state = torch.load(os.path.join(MODELS_DIR, 'pet_pred_resnet50.pth'), map_location=DEVICE)\n",
    "    if 'state_dict' in img_state: img_state = img_state['state_dict']\n",
    "    # FIX: Add 'resnet.' prefix to match the class definition\n",
    "    new_state_dict = {}\n",
    "    for k, v in img_state.items():\n",
    "        \n",
    "        # Case 1: the key is for FC layer\n",
    "        if \"resnet.fc.\" in k:\n",
    "            new_key = k.replace(\"resnet.fc.\", \"fc.\")\n",
    "            new_state_dict[new_key] = v\n",
    "            continue\n",
    "        # Case 2: the key is for the backbone\n",
    "        if not k.startswith('resnet.') and 'fc.' not in k:\n",
    "            new_state_dict['resnet.' + k] = v\n",
    "        else:\n",
    "            # It already matches\n",
    "            new_state_dict[k] = v\n",
    "    \n",
    "    img_model.load_state_dict(new_state_dict)\n",
    "    img_model.eval()\n",
    "\n",
    "    # Text\n",
    "    text_model = TransformerPetClassifier(num_classes=5).to(DEVICE)\n",
    "    txt_state = torch.load(os.path.join(MODELS_DIR, 'best_transformer_model.pth'), map_location=DEVICE)\n",
    "    if 'state_dict' in txt_state: txt_state = txt_state['state_dict']\n",
    "    text_model.load_state_dict(txt_state, strict=False) \n",
    "    text_model.eval()\n",
    "\n",
    "    # 3. Inference Loop\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    dl = DataLoader(EnsembleDataset(df, img_dir, tokenizer, transform), batch_size=32, shuffle=False)\n",
    "\n",
    "    img_features, text_features = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl):\n",
    "            imgs = batch['image'].to(DEVICE)\n",
    "            input_ids, masks = batch['input_ids'].to(DEVICE), batch['attention_mask'].to(DEVICE)\n",
    "            \n",
    "            # Changed extrect emb instead of probs\n",
    "            # Image: Returns (Batch, 2048)\n",
    "            img_emb = img_model(imgs, return_features=True) \n",
    "            # Flatten 4D tensor (N, 2048, 1, 1) -> (N, 2048)\n",
    "            img_emb = img_emb.view(img_emb.size(0), -1)\n",
    "            img_features.extend(img_emb.cpu().numpy())\n",
    "            \n",
    "            # Text: Returns (Batch, 128)\n",
    "            text_emb = text_model(input_ids, masks, return_features=True)\n",
    "            text_features.extend(text_emb.cpu().numpy())\n",
    "\n",
    "    # 4. Concatenate Features: XGB(5) + Text(128) + Image(2048)\n",
    "    # FIX: Removed reshape(-1, 1) and flatten() to align dimensions\n",
    "    return np.hstack([xgb_probs, np.array(text_features), np.array(img_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressor instead?\n",
    "class IntermediateFusionMetaModel(nn.Module):\n",
    "    def __init__(self, xgb_dim=5, text_dim=128, img_dim=2048):\n",
    "        super(IntermediateFusionMetaModel, self).__init__()\n",
    "        \n",
    "        # IDK: Normalize inputs for scaling\n",
    "        self.norm_xgb = nn.BatchNorm1d(xgb_dim)\n",
    "        self.norm_text = nn.BatchNorm1d(text_dim)\n",
    "        self.norm_img = nn.BatchNorm1d(img_dim)\n",
    "        \n",
    "        # Projectors to reduce dimensionality before fusion\n",
    "        self.img_projector = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.text_projector = nn.Sequential(\n",
    "            nn.Linear(text_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion Layer\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(256 + 64 + xgb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1) #1 for single continuous value (reg)\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Slice the input back into components\n",
    "        # x is [xgb(5), text(128), img(2048)]\n",
    "        xgb_start, xgb_end = 0, 5\n",
    "        text_start, text_end = 5, 5+128\n",
    "        img_start = 5+128\n",
    "        \n",
    "        xgb_data = x[:, xgb_start:xgb_end]\n",
    "        text_data = x[:, text_start:text_end]\n",
    "        img_data = x[:, img_start:]\n",
    "        \n",
    "        # IDK Apply Normalization\n",
    "        xgb_data = self.norm_xgb(xgb_data)\n",
    "        text_data = self.norm_text(text_data)\n",
    "        img_data = self.norm_img(img_data)\n",
    "        \n",
    "        # Project\n",
    "        img_emb = self.img_projector(img_data)\n",
    "        text_emb = self.text_projector(text_data)\n",
    "        \n",
    "        # Concatenate and Classify\n",
    "        combined = torch.cat([xgb_data, text_emb, img_emb], dim=1)\n",
    "        return self.fusion(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e11ef",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-Features for Train...\n",
      "Generating features for 11994 samples...\n",
      "Loading XGBoost...\n",
      "Loading DL Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4cd7a9a1f5495396446dca1054f026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
      "cls.predictions.bias                       | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "100%|██████████| 375/375 [07:25<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-Features for Test...\n",
      "Generating features for 2999 samples...\n",
      "Loading XGBoost...\n",
      "Loading DL Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf57778f4ba465d886a14a45ddc2a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
      "cls.predictions.bias                       | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "100%|██████████| 94/94 [01:52<00:00,  1.19s/it]\n",
      "C:\\Users\\tanap\\AppData\\Local\\Temp\\ipykernel_18496\\1794901249.py:27: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:219.)\n",
      "  y_train_tensor = torch.LongTensor(y_train.values).to(DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP Meta-Learner...\n",
      "Epoch 140 Loss: 0.4551\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'raw_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m     outputs = meta_model(X_test_tensor)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m#test_preds = torch.argmax(outputs, dim=1).cpu().numpy()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     test_preds = np.clip(np.round(\u001b[43mraw_preds\u001b[49m), \u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIntermediate Fusion Test Kappa: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcohen_kappa_score(y_test,\u001b[38;5;250m \u001b[39mtest_preds,\u001b[38;5;250m \u001b[39mweights=\u001b[33m'\u001b[39m\u001b[33mquadratic\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'raw_preds' is not defined"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv(os.path.join(DATA_DIR, 'train/train.csv'))\n",
    "\n",
    "# Create Splits\n",
    "train_df, test_df, y_train, y_test = train_test_split(\n",
    "    full_df, full_df['AdoptionSpeed'], test_size=0.2, random_state=42, stratify=full_df['AdoptionSpeed']  # Add stratify? , stratify=full_df['AdoptionSpeed']\n",
    ")\n",
    "# TODO: create a mapping for count encoding rescuerID -> for inference use the rescuer_counts to map \n",
    "rescuer_mapping = pd.read_csv(\"../data/experimental/rescuer_counts_mapping.csv\")\n",
    "rescuer_counts = rescuer_mapping.set_index('RescuerID')['count']\n",
    "\n",
    "train_df['rescuer_count'] = train_df['RescuerID'].map(rescuer_counts).fillna(1)\n",
    "test_df['rescuer_count'] = test_df['RescuerID'].map(rescuer_counts).fillna(1)\n",
    "\n",
    "train_df.drop('RescuerID', axis=1, inplace=True)\n",
    "test_df.drop('RescuerID', axis=1, inplace=True)\n",
    "\n",
    "# Generate Features (The \"Level 1\" Predictions)\n",
    "print(\"Generating Meta-Features for Train...\")\n",
    "X_train_meta = generate_ensemble_features(train_df) \n",
    "\n",
    "print(\"Generating Meta-Features for Test...\")\n",
    "X_test_meta = generate_ensemble_features(test_df)\n",
    "\n",
    "\n",
    "# Prepare Data for PyTorch\n",
    "X_train_tensor = torch.FloatTensor(X_train_meta).to(DEVICE)\n",
    "y_train_tensor = torch.LongTensor(y_train.values).to(DEVICE)\n",
    "X_test_tensor = torch.FloatTensor(X_test_meta).to(DEVICE)\n",
    "\n",
    "y_train_float = y_train_tensor.float().unsqueeze(1) \n",
    "# Training Loop\n",
    "meta_model = IntermediateFusionMetaModel().to(DEVICE)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(meta_model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training MLP Meta-Learner...\")\n",
    "for epoch in range(150): # epochs\n",
    "    optimizer.zero_grad()\n",
    "    outputs = meta_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_float)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0: print(f\"Epoch {epoch} Loss: {loss.item():.4f}\", end='\\r')\n",
    "\n",
    "\n",
    "# Evaluate w/rounding\n",
    "meta_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = meta_model(X_test_tensor)\n",
    "    #test_preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    raw_preds = outputs.cpu().numpy().flatten()\n",
    "    test_preds = np.clip(np.round(raw_preds), 0, 4).astype(int)\n",
    "\n",
    "print(f\"\\nIntermediate Fusion Test Kappa: {cohen_kappa_score(y_test, test_preds, weights='quadratic'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "453450bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding with own Function\n",
      "Standard Rounding Kappa: 0.3314\n",
      "Optimized Rounding Kappa: 0.4205\n",
      "Learned Thresholds: [0.55799874 1.72213393 2.2562546  2.83002484]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "\n",
    "class OptimizedRounder:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]: X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]: X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]: X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]: X_p[i] = 3\n",
    "            else: X_p[i] = 4\n",
    "        \n",
    "        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]: X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]: X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]: X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]: X_p[i] = 3\n",
    "            else: X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "\n",
    "# 1. Get raw float predictions from training set to learn thresholds\n",
    "meta_model.eval()\n",
    "with torch.no_grad():\n",
    "    train_raw_preds = meta_model(X_train_tensor).cpu().numpy().flatten()\n",
    "    test_raw_preds = meta_model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# 2. Fit Rounder\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(train_raw_preds, y_train)\n",
    "\n",
    "# 3. Predict with dynamic thresholds\n",
    "test_preds_optimized = optR.predict(test_raw_preds, optR.coef_['x']).astype(int)\n",
    "print (\"Rounding with own Function\")\n",
    "print(f\"Standard Rounding Kappa: {cohen_kappa_score(y_test, np.clip(np.round(test_raw_preds), 0, 4), weights='quadratic'):.4f}\")\n",
    "print(f\"Optimized Rounding Kappa: {cohen_kappa_score(y_test, test_preds_optimized, weights='quadratic'):.4f}\")\n",
    "print(f\"Learned Thresholds: {optR.coef_['x']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fedb6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding with oprounder library\n",
      "Optimal thresholds: [1.0198270690051536, 1.8038770526156236, 2.190740728654829, 2.70849811533068]\n",
      "Optimal Rounding QWK: 0.4145\n",
      "Standard Rounding QWK: 0.3314\n"
     ]
    }
   ],
   "source": [
    "from oprounder import OptimizedRounder\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "meta_model.eval()\n",
    "with torch.no_grad():\n",
    "    train_raw_preds = meta_model(X_train_tensor).cpu().numpy().flatten()\n",
    "    test_raw_preds = meta_model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Fit the Optimized Rounder on Training Data\n",
    "rounder = OptimizedRounder(n_classes=y_train.nunique(), n_trials=100)\n",
    "rounder.fit(train_raw_preds, y_train) #TODO: Change this appro.\n",
    "\n",
    "print (\"Rounding with oprounder library\")\n",
    "# View the learned thresholds\n",
    "print(f'Optimal thresholds: {rounder.thresholds}')\n",
    "\n",
    "# Predict on Test Data using the new thresholds\n",
    "prediction_reg_optimized = rounder.predict(test_raw_preds) # use the new threshold to pick label\n",
    "\n",
    "# Compare how the new threshold improve kappa\n",
    "kappa = cohen_kappa_score(y_test, prediction_reg_optimized, weights='quadratic')\n",
    "print(f'Optimal Rounding QWK: {kappa:.4f}')\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, np.clip(np.round(test_raw_preds), 0, 4), weights='quadratic')\n",
    "print(f'Standard Rounding QWK: {kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8214958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Meta-Features for Test Data...\n",
      "Generating features for 3972 samples...\n",
      "Loading XGBoost...\n",
      "Loading DL Models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Work\\DataScience\\AdoptMe\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e029c7a084040518a43f1e800709529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
      "cls.predictions.bias                       | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "100%|██████████| 125/125 [02:26<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to ../submission_v1_intermediate.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluate prediction on test.csv!\n",
    "# Load test data\n",
    "inference_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "# Generate meta-features for test data\n",
    "print(\"Generating Meta-Features for Test Data...\")\n",
    "rescuer_counts = pd.read_csv(\"../data/experimental/rescuer_counts_mapping.csv\")\n",
    "inference_df['rescuer_count'] = inference_df['RescuerID'].map(rescuer_counts[\"RescuerID\"]).fillna(0)\n",
    "inference_df.drop(['RescuerID'],axis=1,  inplace=True)\n",
    "\n",
    "X_test_final_meta = generate_ensemble_features(inference_df, img_dir=IMAGE_DIR)\n",
    "\n",
    "# Convert to tensor\n",
    "X_test_final_tensor = torch.FloatTensor(X_test_final_meta).to(DEVICE)\n",
    "\n",
    "# Make predictions using trained meta model\n",
    "meta_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = meta_model(X_test_final_tensor)\n",
    "    final_test_preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'PetID': inference_df['PetID'],\n",
    "    'AdoptionSpeed': final_test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"../submission_v1_intermediate.csv\", index=False)\n",
    "print(f\"Submission saved to {\"../submission_v1_intermediate.csv\"}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
