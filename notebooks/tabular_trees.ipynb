{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051407aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tuning!\n",
    "# ==========================================\n",
    "# 1. XGBoost Regressor (Uses X_train_xgb)\n",
    "# ==========================================\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist' # Faster\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_xgb, y_train,\n",
    "    eval_set=[(X_test_xgb, y_test)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. LightGBM Regressor (Uses X_train_lgb)\n",
    "# ==========================================\n",
    "print(\"\\nTraining LightGBM...\")\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=-1, # Leaf-wise growth\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train_lgb, y_train,\n",
    "    eval_set=[(X_test_lgb, y_test)],\n",
    "    # callbacks=[lgb.early_stopping(stopping_rounds=50)] # For newer versions of LGBM\n",
    "    early_stopping_rounds=50, \n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 3. CatBoost Regressor (Uses X_train_cat)\n",
    "# ==========================================\n",
    "print(\"\\nTraining CatBoost...\")\n",
    "# Identify categorical features indices for CatBoost\n",
    "cat_features_indices = [X_train_cat.columns.get_loc(c) for c in \n",
    "                        ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', \n",
    "                         'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \n",
    "                         'Sterilized', 'Health', 'State', 'RescuerID'] if c in X_train_cat.columns]\n",
    "\n",
    "# Identify Text feature indices\n",
    "text_features_indices = [X_train_cat.columns.get_loc('Description')] if 'Description' in X_train_cat.columns else []\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "    loss_function='RMSE',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    task_type='CPU' # Change to GPU if available\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    X_train_cat, y_train,\n",
    "    cat_features=cat_features_indices,\n",
    "    text_features=text_features_indices, # Native text support!\n",
    "    eval_set=(X_test_cat, y_test),\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw predictions\n",
    "pred_xgb = xgb_model.predict(X_test_xgb)\n",
    "pred_lgb = lgb_model.predict(X_test_lgb)\n",
    "pred_cat = cat_model.predict(X_test_cat)\n",
    "\n",
    "# Simple Average Blend\n",
    "final_blend_continuous = (pred_xgb + pred_lgb + pred_cat) / 3\n",
    "\n",
    "# Now apply your OptimizedRounder to 'final_blend_continuous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_prediction):\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Kappa Score: {cohen_kappa_score(model_prediction, y_test, weights='quadratic'):.4f}\")\n",
    "    print(f\"Accuracy Score: {accuracy_score(model_prediction, y_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
