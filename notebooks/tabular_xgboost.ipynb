{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8d75b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, accuracy_score\n",
    "pd.set_option('display.max_columns', None)\n",
    "import joblib\n",
    "\n",
    "pet_df = pd.read_csv(\"../data/train/train.csv\") #Beware of directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028d85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>name_length</th>\n",
       "      <th>description_length</th>\n",
       "      <th>is_mixed_breed</th>\n",
       "      <th>num_colors</th>\n",
       "      <th>is_free</th>\n",
       "      <th>fee_per_pet</th>\n",
       "      <th>total_media</th>\n",
       "      <th>has_health_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age Breed1 Breed2 Gender Color1 Color2 Color3 MaturitySize FurLength  \\\n",
       "0    2    3    299      0      1      1      7      0            1         1   \n",
       "1    2    1    265      0      1      1      2      0            2         2   \n",
       "2    1    1    307      0      1      2      7      0            2         2   \n",
       "3    1    4    307      0      2      1      2      0            2         1   \n",
       "4    1    1    307      0      1      1      0      0            2         1   \n",
       "\n",
       "  Vaccinated Dewormed Sterilized Health  Quantity  Fee  State  \\\n",
       "0          2        2          2      1         1  100  41326   \n",
       "1          3        3          3      1         1    0  41401   \n",
       "2          1        1          2      1         1    0  41326   \n",
       "3          1        1          2      1         1  150  41401   \n",
       "4          2        2          2      1         1    0  41326   \n",
       "\n",
       "                          RescuerID  VideoAmt  PhotoAmt  AdoptionSpeed  \\\n",
       "0  8480853f516546f6cf33aa88cd76c379         0       1.0              2   \n",
       "1  3082c7125d8fb66f7dd4bff4192c8b14         0       2.0              0   \n",
       "2  fa90fa5b1ee11c86938398b60abc32cb         0       7.0              3   \n",
       "3  9238e4f44c71a75282e62f7136c6b240         0       8.0              2   \n",
       "4  95481e953f8aed9ec3d16fc4509537e8         0       3.0              2   \n",
       "\n",
       "   name_length  description_length  is_mixed_breed  num_colors  is_free  \\\n",
       "0          6.0               359.0               0           2        0   \n",
       "1         11.0               118.0               0           2        1   \n",
       "2          6.0               393.0               0           2        1   \n",
       "3          4.0               146.0               0           2        0   \n",
       "4          6.0               390.0               0           1        1   \n",
       "\n",
       "   fee_per_pet  total_media  has_health_issue  \n",
       "0        100.0          1.0                 0  \n",
       "1          0.0          2.0                 0  \n",
       "2          0.0          7.0                 0  \n",
       "3        150.0          8.0                 0  \n",
       "4          0.0          3.0                 0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: lookup sentiment\n",
    "# TODO: text feature (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Target encoding\n",
    "def featurize_table(data_df, tfidf_vectorizer=None, is_train=True):\n",
    "    tabular_df = data_df.copy()\n",
    "    # Namelength\n",
    "    tabular_df[\"name_length\"] = tabular_df['Name'].str.len().fillna(0)\n",
    "    \n",
    "    # Description length\n",
    "    tabular_df['description_length'] = tabular_df['Description'].str.len().fillna(0)\n",
    "    \n",
    "    \n",
    "    # Is Mixed Breed? (Breed2 is not 0)\n",
    "    tabular_df['is_mixed_breed'] = (tabular_df['Breed2'] != 0).astype(int)\n",
    "    \n",
    "    # Number of Colors (Count non-zero color columns)\n",
    "    tabular_df['num_colors'] = (tabular_df[['Color1', 'Color2', 'Color3']] != 0).sum(axis=1)\n",
    "    \n",
    "    # Is Free? (Fee is 0)\n",
    "    tabular_df['is_free'] = (tabular_df['Fee'] == 0).astype(int)\n",
    "\n",
    "    # Fee per Pet (Normizalized for litters)\n",
    "    tabular_df['fee_per_pet'] = tabular_df['Fee'] / tabular_df['Quantity'].replace(0, 1)\n",
    "\n",
    "    # Total Media (Engagement proxy)\n",
    "    tabular_df['total_media'] = tabular_df['PhotoAmt'] + tabular_df['VideoAmt']\n",
    "\n",
    "    # Health Issue Flag (Health > 1 implies injury or condition)\n",
    "    tabular_df['has_health_issue'] = (tabular_df['Health'] > 1).astype(int)\n",
    "    # --------------------\n",
    "    \n",
    "    \n",
    "    # Encode state/breed as categories\n",
    "    # ADDED 'Type' to this list\n",
    "    cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', \n",
    "                    'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', \n",
    "                    'Sterilized', 'Health', 'State']\n",
    "    for col in cat_cols:\n",
    "        if col in tabular_df.columns:\n",
    "            tabular_df[col] = tabular_df[col].astype('category')\n",
    "        \n",
    "    # Sentiment Analysis from JSON\n",
    "    #print(\"Extracting sentiment features...\")\n",
    "    #sentiment_features = tabular_df['PetID'].apply(lambda x: extract_sentiment(x, True))\n",
    "    #tabular_df['sentiment_score'] = [x[0] for x in sentiment_features]\n",
    "    #tabular_df['sentiment_magnitude'] = [x[1] for x in sentiment_features]\n",
    "    \n",
    "    # TF-IDF\n",
    "    descriptions = tabular_df['Description']\n",
    "    # Drop unused columns (Including RescuerID now)\n",
    "    tabular_df.drop(['Name', 'PetID', 'Description'], axis=1, inplace=True)\n",
    "    \n",
    "    if is_train:\n",
    "        tfidf = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "        tfidf_matrix = tfidf.fit_transform(descriptions)\n",
    "        \n",
    "        # Create a Dataframe for tfidf features\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f\"tfidf_{i}\" for i in range(100)])\n",
    "        # Return features, also vectorizer to be used on inference\n",
    "        return pd.concat([tabular_df.reset_index(drop=True), tfidf_df], axis=1), tfidf\n",
    "    else:\n",
    "        # Use existing vectorizer\n",
    "        tfidf_matrix = tfidf_vectorizer.transform(descriptions)\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f\"tfidf_{i}\" for i in range(100)])\n",
    "        return pd.concat([tabular_df.reset_index(drop=True), tfidf_df], axis=1)\n",
    "    return tabular_df\n",
    "\n",
    "pet_features = featurize_table(pet_df)\n",
    "pet_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8be96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data from train.csv\n",
    "X = pet_features.drop(['AdoptionSpeed'], axis=1)\n",
    "y = pet_features['AdoptionSpeed'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TODO: create a mapping for count encoding rescuerID\n",
    "rescuer_counts = X_train[\"RescuerID\"].value_counts()\n",
    "X_train['rescuer_count'] = X_train['RescuerID'].map(rescuer_counts)\n",
    "\n",
    "X_test['rescuer_count'] = X_test['RescuerID'].map(rescuer_counts).fillna(0)\n",
    "\n",
    "X_train.drop('RescuerID', axis=1, inplace=True)\n",
    "X_test.drop('RescuerID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9575da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "prediction_dummy = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cae63c",
   "metadata": {},
   "source": [
    "# Pure XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64db2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost (Basic)\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective='clf:accuracy',\n",
    "    n_estimators = 100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=2,\n",
    "    #early_stopping_rounds=50, # Use early stoppage to mitigate overfitting\n",
    "    n_jobs=-1 # enables parallel on all cores for faster training\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "prediction_xgb = xgb_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf580ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparameters = {\\n    \\'n_estimators\\': [50, 100, 200, 250],\\n    \\'learning_rate\\': [0.01, 0.05, 0.1, 0.2],\\n    \\'max_depth\\': [5, 7, 9, 12],\\n    \\'subsample\\': [0.7, 0.8, 0.9, 1.0],\\n    \\'colsample_bytree\\': [0.6, 0.7, 0.8, 0.9, 1.0]\\n}\\n\\nrscv = RandomizedSearchCV(\\n    estimator=xgb.XGBClassifier(objective=\"multi:softprob\", # softmax only return the winning class, this will return a vector we want\\n                                eval_metric = \"mlogloss\"), # validation metric for early stoppage in training\\n    param_distributions=parameters,\\n    scoring=make_scorer(cohen_kappa_score, weights=\\'quadratic\\'), # Decider for best model from rscv\\n    n_iter=50, # Try n random combinations\\n    cv=5,\\n    verbose=1,\\n    random_state=42,\\n    n_jobs=-1 # Parallel processing\\n)\\n\\nrscv.fit(X_train, y_train)\\nprint (f\"Best Parameters: {rscv.best_params_}\")\\nprint (f\"Average Quadratic Weighted Kappa Score on all validation folds: {rscv.best_score_:.4f}\")\\nxgb_bestmodel = rscv.best_estimator_\\nprediction_xgb_best = xgb_bestmodel.predict(X_test) # Get class prediction\\nprobs_xgb_best = xgb_bestmodel.predict_proba(X_test) # Get probs for all classes\\n\\nprediction_train = xgb_bestmodel.predict(X_train)\\nprint(f\"Real Kappa on Training Set: {cohen_kappa_score(prediction_train, y_train, weights=\\'quadratic\\'):.4f}\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost (Tuned)\n",
    "\"\"\"\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100, 200, 250],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [5, 7, 9, 12],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective=\"multi:softprob\", # softmax only return the winning class, this will return a vector we want\n",
    "                                eval_metric = \"mlogloss\"), # validation metric for early stoppage in training\n",
    "    param_distributions=parameters,\n",
    "    scoring=make_scorer(cohen_kappa_score, weights='quadratic'), # Decider for best model from rscv\n",
    "    n_iter=50, # Try n random combinations\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1 # Parallel processing\n",
    ")\n",
    "\n",
    "rscv.fit(X_train, y_train)\n",
    "print (f\"Best Parameters: {rscv.best_params_}\")\n",
    "print (f\"Average Quadratic Weighted Kappa Score on all validation folds: {rscv.best_score_:.4f}\")\n",
    "xgb_bestmodel = rscv.best_estimator_\n",
    "prediction_xgb_best = xgb_bestmodel.predict(X_test) # Get class prediction\n",
    "probs_xgb_best = xgb_bestmodel.predict_proba(X_test) # Get probs for all classes\n",
    "\n",
    "prediction_train = xgb_bestmodel.predict(X_train)\n",
    "print(f\"Real Kappa on Training Set: {cohen_kappa_score(prediction_train, y_train, weights='quadratic'):.4f}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc83a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 13:20:51,718]\u001b[0m A new study created in memory with name: no-name-07ee7ee0-80a9-4367-816d-e5e849ab6b5f\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:20:53,851]\u001b[0m Trial 0 finished with value: 0.41887356708810464 and parameters: {'n_estimators': 594, 'learning_rate': 0.052416740437630116, 'max_depth': 7, 'subsample': 0.7256001151892301, 'colsample_bytree': 0.7723742394196941, 'min_child_weight': 1, 'reg_alpha': 5.993881094533176, 'reg_lambda': 9.613353892492805}. Best is trial 0 with value: 0.41887356708810464.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:20:56,721]\u001b[0m Trial 1 finished with value: 0.4175090459189509 and parameters: {'n_estimators': 436, 'learning_rate': 0.016850437230908403, 'max_depth': 9, 'subsample': 0.7408669885947923, 'colsample_bytree': 0.9329672262649585, 'min_child_weight': 5, 'reg_alpha': 2.6849083605292465, 'reg_lambda': 6.571234395415612}. Best is trial 0 with value: 0.41887356708810464.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:20:58,807]\u001b[0m Trial 2 finished with value: 0.4249229941086754 and parameters: {'n_estimators': 309, 'learning_rate': 0.018050315168904756, 'max_depth': 9, 'subsample': 0.8652895144025514, 'colsample_bytree': 0.795291166523391, 'min_child_weight': 4, 'reg_alpha': 3.2020322284657334, 'reg_lambda': 9.605270108620035}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:20:59,740]\u001b[0m Trial 3 finished with value: 0.4088883860175957 and parameters: {'n_estimators': 373, 'learning_rate': 0.1297241410696234, 'max_depth': 11, 'subsample': 0.7168067536521109, 'colsample_bytree': 0.9773976717801192, 'min_child_weight': 6, 'reg_alpha': 1.2387301087902725, 'reg_lambda': 3.863964776905917}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:01,897]\u001b[0m Trial 4 finished with value: 0.3929246523991794 and parameters: {'n_estimators': 405, 'learning_rate': 0.0637218028949666, 'max_depth': 8, 'subsample': 0.768442926658072, 'colsample_bytree': 0.7135489076615913, 'min_child_weight': 1, 'reg_alpha': 9.893061051140714, 'reg_lambda': 5.277101431982228}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:07,173]\u001b[0m Trial 5 finished with value: 0.4209638238101485 and parameters: {'n_estimators': 673, 'learning_rate': 0.005206446620789206, 'max_depth': 9, 'subsample': 0.6693804282442812, 'colsample_bytree': 0.8427499081522649, 'min_child_weight': 3, 'reg_alpha': 0.6247379856130852, 'reg_lambda': 1.011897403427141}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:10,184]\u001b[0m Trial 6 finished with value: 0.4169415800942434 and parameters: {'n_estimators': 538, 'learning_rate': 0.00867129255433213, 'max_depth': 7, 'subsample': 0.718648582508821, 'colsample_bytree': 0.8728548910592986, 'min_child_weight': 9, 'reg_alpha': 1.5214580510442155, 'reg_lambda': 4.3261072817572535}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:14,532]\u001b[0m Trial 7 finished with value: 0.40228951977210026 and parameters: {'n_estimators': 885, 'learning_rate': 0.017246392090641945, 'max_depth': 8, 'subsample': 0.6981300090804857, 'colsample_bytree': 0.7280654916849121, 'min_child_weight': 8, 'reg_alpha': 9.026619172598334, 'reg_lambda': 5.499798124265013}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:15,656]\u001b[0m Trial 8 finished with value: 0.4168768080012897 and parameters: {'n_estimators': 673, 'learning_rate': 0.16087940004293283, 'max_depth': 10, 'subsample': 0.7439444274598789, 'colsample_bytree': 0.8972838202445577, 'min_child_weight': 5, 'reg_alpha': 7.8061119038045845, 'reg_lambda': 1.4429190807211123}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:18,996]\u001b[0m Trial 9 finished with value: 0.4124307983192649 and parameters: {'n_estimators': 624, 'learning_rate': 0.005344785802049376, 'max_depth': 7, 'subsample': 0.8489093552812865, 'colsample_bytree': 0.6017854379469539, 'min_child_weight': 9, 'reg_alpha': 0.9509247556420031, 'reg_lambda': 4.13400527222335}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:19,582]\u001b[0m Trial 10 finished with value: 0.3820515707690575 and parameters: {'n_estimators': 235, 'learning_rate': 0.02525302860624919, 'max_depth': 3, 'subsample': 0.9927964550230011, 'colsample_bytree': 0.6288510929731067, 'min_child_weight': 3, 'reg_alpha': 4.096467802800582, 'reg_lambda': 9.846531888772986}. Best is trial 2 with value: 0.4249229941086754.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:28,124]\u001b[0m Trial 11 finished with value: 0.44197281719641035 and parameters: {'n_estimators': 860, 'learning_rate': 0.009037735056896395, 'max_depth': 12, 'subsample': 0.6171012303459075, 'colsample_bytree': 0.822466124628807, 'min_child_weight': 3, 'reg_alpha': 0.06688797397296709, 'reg_lambda': 0.18976145197431737}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:37,821]\u001b[0m Trial 12 finished with value: 0.4052797770787828 and parameters: {'n_estimators': 971, 'learning_rate': 0.011233639484642101, 'max_depth': 12, 'subsample': 0.6003388955796345, 'colsample_bytree': 0.8066316737886777, 'min_child_weight': 3, 'reg_alpha': 3.6608295627697607, 'reg_lambda': 7.826379545923983}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:40,217]\u001b[0m Trial 13 finished with value: 0.42775263951734543 and parameters: {'n_estimators': 864, 'learning_rate': 0.03492110178063037, 'max_depth': 5, 'subsample': 0.8591807657916559, 'colsample_bytree': 0.7637686513462009, 'min_child_weight': 4, 'reg_alpha': 5.987060778367777, 'reg_lambda': 2.5000575320731517}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:42,731]\u001b[0m Trial 14 finished with value: 0.4132008589818005 and parameters: {'n_estimators': 811, 'learning_rate': 0.045375164203813184, 'max_depth': 4, 'subsample': 0.9340571766133581, 'colsample_bytree': 0.6967582712441281, 'min_child_weight': 6, 'reg_alpha': 5.927506226116836, 'reg_lambda': 0.034047478361707045}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:43,901]\u001b[0m Trial 15 finished with value: 0.42521784878482405 and parameters: {'n_estimators': 804, 'learning_rate': 0.08838770796789713, 'max_depth': 5, 'subsample': 0.8359620794945666, 'colsample_bytree': 0.7609540780029909, 'min_child_weight': 2, 'reg_alpha': 7.082810246181953, 'reg_lambda': 2.53905432998197}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:47,390]\u001b[0m Trial 16 finished with value: 0.423514005749808 and parameters: {'n_estimators': 982, 'learning_rate': 0.031775182619738176, 'max_depth': 5, 'subsample': 0.9113805702587114, 'colsample_bytree': 0.6751446614296612, 'min_child_weight': 4, 'reg_alpha': 4.9591089127223436, 'reg_lambda': 2.5840442172567704}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:50,400]\u001b[0m Trial 17 finished with value: 0.39829276798797786 and parameters: {'n_estimators': 789, 'learning_rate': 0.009111310660702494, 'max_depth': 5, 'subsample': 0.6013877108755211, 'colsample_bytree': 0.838643097773322, 'min_child_weight': 7, 'reg_alpha': 7.312865449059947, 'reg_lambda': 0.021842411499768843}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:53,939]\u001b[0m Trial 18 finished with value: 0.41551639142223307 and parameters: {'n_estimators': 886, 'learning_rate': 0.03565681803982986, 'max_depth': 12, 'subsample': 0.8010753567328095, 'colsample_bytree': 0.928204595165673, 'min_child_weight': 4, 'reg_alpha': 2.292858808544682, 'reg_lambda': 2.528125681079642}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:54,879]\u001b[0m Trial 19 finished with value: 0.42859281997529297 and parameters: {'n_estimators': 738, 'learning_rate': 0.07593737770083753, 'max_depth': 6, 'subsample': 0.6549327466602872, 'colsample_bytree': 0.7473312336564022, 'min_child_weight': 2, 'reg_alpha': 0.04582776028429182, 'reg_lambda': 1.2567435659802235}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:55,678]\u001b[0m Trial 20 finished with value: 0.42131195344041317 and parameters: {'n_estimators': 725, 'learning_rate': 0.09643636474969661, 'max_depth': 6, 'subsample': 0.6487053629956507, 'colsample_bytree': 0.8283737572170403, 'min_child_weight': 2, 'reg_alpha': 0.32892403153481825, 'reg_lambda': 1.2536549941049757}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:56,831]\u001b[0m Trial 21 finished with value: 0.42361802420986117 and parameters: {'n_estimators': 888, 'learning_rate': 0.06827323785847297, 'max_depth': 6, 'subsample': 0.6478988998264033, 'colsample_bytree': 0.7483643858755529, 'min_child_weight': 2, 'reg_alpha': 0.17597442173882222, 'reg_lambda': 1.555819662741938}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:21:58,666]\u001b[0m Trial 22 finished with value: 0.4134764712090827 and parameters: {'n_estimators': 752, 'learning_rate': 0.023031144433405384, 'max_depth': 3, 'subsample': 0.6343134843200381, 'colsample_bytree': 0.6555664705237896, 'min_child_weight': 3, 'reg_alpha': 4.828783697609099, 'reg_lambda': 3.061769729488051}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:00,668]\u001b[0m Trial 23 finished with value: 0.4179464016862391 and parameters: {'n_estimators': 859, 'learning_rate': 0.04141160098778547, 'max_depth': 6, 'subsample': 0.8013320219664933, 'colsample_bytree': 0.7823211460264909, 'min_child_weight': 1, 'reg_alpha': 6.183207775858665, 'reg_lambda': 0.7004248015823658}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:01,732]\u001b[0m Trial 24 finished with value: 0.411783261057979 and parameters: {'n_estimators': 931, 'learning_rate': 0.09686971497226372, 'max_depth': 4, 'subsample': 0.6823188921590065, 'colsample_bytree': 0.7375536488064229, 'min_child_weight': 2, 'reg_alpha': 2.173676242429746, 'reg_lambda': 2.055955767000245}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:03,845]\u001b[0m Trial 25 finished with value: 0.41687205495666235 and parameters: {'n_estimators': 718, 'learning_rate': 0.01241292879995987, 'max_depth': 4, 'subsample': 0.8839361987224839, 'colsample_bytree': 0.8072701723697031, 'min_child_weight': 4, 'reg_alpha': 4.249264766215495, 'reg_lambda': 3.364372562626573}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:05,421]\u001b[0m Trial 26 finished with value: 0.4232800794350079 and parameters: {'n_estimators': 828, 'learning_rate': 0.06159730890111639, 'max_depth': 11, 'subsample': 0.9624771383890249, 'colsample_bytree': 0.8602176945847662, 'min_child_weight': 5, 'reg_alpha': 1.8664173049018118, 'reg_lambda': 0.5485515392299469}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:07,656]\u001b[0m Trial 27 finished with value: 0.41299577857807246 and parameters: {'n_estimators': 515, 'learning_rate': 0.025454311782099955, 'max_depth': 6, 'subsample': 0.7749546303915289, 'colsample_bytree': 0.6873525218311636, 'min_child_weight': 3, 'reg_alpha': 0.039039064807642784, 'reg_lambda': 2.006131649414077}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:11,084]\u001b[0m Trial 28 finished with value: 0.4156738989077069 and parameters: {'n_estimators': 945, 'learning_rate': 0.007183173204307204, 'max_depth': 5, 'subsample': 0.8258630441465272, 'colsample_bytree': 0.7646087849165681, 'min_child_weight': 2, 'reg_alpha': 3.0861635079124383, 'reg_lambda': 0.6153428182332058}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:11,709]\u001b[0m Trial 29 finished with value: 0.39722266928629346 and parameters: {'n_estimators': 603, 'learning_rate': 0.1975813776523605, 'max_depth': 8, 'subsample': 0.6289351320238762, 'colsample_bytree': 0.888308775936745, 'min_child_weight': 1, 'reg_alpha': 5.701146097823763, 'reg_lambda': 1.8678955409162366}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:14,173]\u001b[0m Trial 30 finished with value: 0.39934880957121277 and parameters: {'n_estimators': 758, 'learning_rate': 0.048527133630802535, 'max_depth': 10, 'subsample': 0.9098115239435122, 'colsample_bytree': 0.7810879749875759, 'min_child_weight': 10, 'reg_alpha': 6.720295290821453, 'reg_lambda': 6.172517421717458}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:15,403]\u001b[0m Trial 31 finished with value: 0.4241017058119547 and parameters: {'n_estimators': 831, 'learning_rate': 0.09281271505694755, 'max_depth': 5, 'subsample': 0.8346665455623251, 'colsample_bytree': 0.7580110869434615, 'min_child_weight': 2, 'reg_alpha': 8.024801185689286, 'reg_lambda': 2.8201516127843234}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:16,699]\u001b[0m Trial 32 finished with value: 0.41231568769639826 and parameters: {'n_estimators': 779, 'learning_rate': 0.07876675434167678, 'max_depth': 4, 'subsample': 0.8846504575329779, 'colsample_bytree': 0.7277091414198789, 'min_child_weight': 1, 'reg_alpha': 6.83057815222492, 'reg_lambda': 3.3827570971082155}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:17,725]\u001b[0m Trial 33 finished with value: 0.43036749313294864 and parameters: {'n_estimators': 915, 'learning_rate': 0.13278390990766445, 'max_depth': 6, 'subsample': 0.8568715998260961, 'colsample_bytree': 0.8100052477237939, 'min_child_weight': 4, 'reg_alpha': 8.278884886268232, 'reg_lambda': 2.2756579878063277}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:18,700]\u001b[0m Trial 34 finished with value: 0.4211739476784865 and parameters: {'n_estimators': 911, 'learning_rate': 0.1346893080885024, 'max_depth': 7, 'subsample': 0.862600484406084, 'colsample_bytree': 0.8177212506419805, 'min_child_weight': 5, 'reg_alpha': 8.656718094457245, 'reg_lambda': 1.2183005490583503}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:19,870]\u001b[0m Trial 35 finished with value: 0.43121554016495645 and parameters: {'n_estimators': 683, 'learning_rate': 0.12279280614647864, 'max_depth': 6, 'subsample': 0.7674658383084535, 'colsample_bytree': 0.7896461596531478, 'min_child_weight': 4, 'reg_alpha': 9.989082073939539, 'reg_lambda': 8.449826609448843}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:21,216]\u001b[0m Trial 36 finished with value: 0.4128142692186041 and parameters: {'n_estimators': 519, 'learning_rate': 0.1423442128493597, 'max_depth': 7, 'subsample': 0.7533909658669028, 'colsample_bytree': 0.7947381316620001, 'min_child_weight': 6, 'reg_alpha': 9.748527527651738, 'reg_lambda': 8.617961593373103}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:22,582]\u001b[0m Trial 37 finished with value: 0.3899530045723233 and parameters: {'n_estimators': 671, 'learning_rate': 0.12065972159779652, 'max_depth': 9, 'subsample': 0.6982566212731991, 'colsample_bytree': 0.8545250089341474, 'min_child_weight': 5, 'reg_alpha': 9.29337920228222, 'reg_lambda': 7.019386211737629}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:23,532]\u001b[0m Trial 38 finished with value: 0.41545351391806085 and parameters: {'n_estimators': 562, 'learning_rate': 0.10976009680329991, 'max_depth': 6, 'subsample': 0.6743689844378089, 'colsample_bytree': 0.9150889505628997, 'min_child_weight': 3, 'reg_alpha': 8.578947943815765, 'reg_lambda': 4.796726592547092}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:24,187]\u001b[0m Trial 39 finished with value: 0.41399307971091537 and parameters: {'n_estimators': 449, 'learning_rate': 0.19889586543444876, 'max_depth': 8, 'subsample': 0.7750617906514501, 'colsample_bytree': 0.7140084678303119, 'min_child_weight': 4, 'reg_alpha': 1.2116254862332818, 'reg_lambda': 8.707718585695304}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:25,028]\u001b[0m Trial 40 finished with value: 0.41041151395950826 and parameters: {'n_estimators': 703, 'learning_rate': 0.15866423036085653, 'max_depth': 7, 'subsample': 0.6257872110606336, 'colsample_bytree': 0.9681041501348414, 'min_child_weight': 7, 'reg_alpha': 9.818044404581387, 'reg_lambda': 6.346523192389162}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:26,897]\u001b[0m Trial 41 finished with value: 0.41597968045485734 and parameters: {'n_estimators': 838, 'learning_rate': 0.05832326966390776, 'max_depth': 6, 'subsample': 0.8168098183550161, 'colsample_bytree': 0.7837057207073124, 'min_child_weight': 4, 'reg_alpha': 7.972114248737553, 'reg_lambda': 3.704525765821872}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:27,869]\u001b[0m Trial 42 finished with value: 0.40875746170258676 and parameters: {'n_estimators': 998, 'learning_rate': 0.07238125422935955, 'max_depth': 5, 'subsample': 0.7271736720058337, 'colsample_bytree': 0.8174315008833741, 'min_child_weight': 4, 'reg_alpha': 0.8427459361059555, 'reg_lambda': 0.8865719504292324}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:30,641]\u001b[0m Trial 43 finished with value: 0.4211499028305621 and parameters: {'n_estimators': 630, 'learning_rate': 0.013833913487282355, 'max_depth': 6, 'subsample': 0.869046973553101, 'colsample_bytree': 0.7937724856706545, 'min_child_weight': 3, 'reg_alpha': 5.4257388861238525, 'reg_lambda': 1.9624748260624625}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:31,747]\u001b[0m Trial 44 finished with value: 0.4163716920706013 and parameters: {'n_estimators': 873, 'learning_rate': 0.10961457751200863, 'max_depth': 7, 'subsample': 0.9042367437924085, 'colsample_bytree': 0.8454262348795089, 'min_child_weight': 5, 'reg_alpha': 9.330779061681515, 'reg_lambda': 4.655527734725965}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:36,984]\u001b[0m Trial 45 finished with value: 0.4180269048771348 and parameters: {'n_estimators': 946, 'learning_rate': 0.019894950339841174, 'max_depth': 10, 'subsample': 0.7897100552972658, 'colsample_bytree': 0.8752353978490275, 'min_child_weight': 3, 'reg_alpha': 8.768247631824668, 'reg_lambda': 5.332075958929732}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:38,377]\u001b[0m Trial 46 finished with value: 0.3904260125743779 and parameters: {'n_estimators': 673, 'learning_rate': 0.1582433363723316, 'max_depth': 11, 'subsample': 0.7049860219610883, 'colsample_bytree': 0.7469666860571257, 'min_child_weight': 6, 'reg_alpha': 7.584578082074107, 'reg_lambda': 0.36006413959227024}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:39,854]\u001b[0m Trial 47 finished with value: 0.4143794645625465 and parameters: {'n_estimators': 760, 'learning_rate': 0.05484476073995344, 'max_depth': 7, 'subsample': 0.8504238721962561, 'colsample_bytree': 0.7189322515928418, 'min_child_weight': 4, 'reg_alpha': 1.6358097336701687, 'reg_lambda': 1.5819083331719148}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:42,536]\u001b[0m Trial 48 finished with value: 0.4251966113017338 and parameters: {'n_estimators': 911, 'learning_rate': 0.03932828125753528, 'max_depth': 8, 'subsample': 0.940604473093175, 'colsample_bytree': 0.7716215847388453, 'min_child_weight': 5, 'reg_alpha': 8.251380370745155, 'reg_lambda': 7.405817381625561}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n",
      "\u001b[32m[I 2026-02-15 13:22:44,908]\u001b[0m Trial 49 finished with value: 0.40535751747328264 and parameters: {'n_estimators': 645, 'learning_rate': 0.028032255487191744, 'max_depth': 5, 'subsample': 0.6580682240950692, 'colsample_bytree': 0.8316437794478552, 'min_child_weight': 3, 'reg_alpha': 6.458351504397686, 'reg_lambda': 9.420833451534127}. Best is trial 11 with value: 0.44197281719641035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial value: 0.44197281719641035\n",
      "Best params: {'n_estimators': 860, 'learning_rate': 0.009037735056896395, 'max_depth': 12, 'subsample': 0.6171012303459075, 'colsample_bytree': 0.822466124628807, 'min_child_weight': 3, 'reg_alpha': 0.06688797397296709, 'reg_lambda': 0.18976145197431737}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_optuna.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter-tuning w/Optuna\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import torch\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'num_class': 5,\n",
    "        'tree_method': 'hist', # Faster training\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu', # Use GPU if available\n",
    "        # Tuning parameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000), # More trees, but early stopping handles it\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Split for early stopping (Optuna needs a validation set)\n",
    "    # Using specific validation set (futher split from train set)\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, \n",
    "                                                #stratify=y_train\n",
    "                                                )\n",
    "\n",
    "    # Choose regressor if trying to use with optimied rounder\n",
    "    model = xgb.XGBClassifier(**params, early_stopping_rounds=50)\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_val)\n",
    "    kappa = cohen_kappa_score(y_val, preds, weights='quadratic')\n",
    "    return kappa\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50) # Run 50 smart trials\n",
    "\n",
    "print(f\"Best trial value: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "# Use best params\n",
    "best_params = study.best_params\n",
    "# Add fixed params back\n",
    "best_params['objective'] = 'multi:softprob'\n",
    "best_params['num_class'] = 5\n",
    "\n",
    "xgb_optuna = xgb.XGBClassifier(**best_params)\n",
    "xgb_optuna.fit(X_train, y_train) \n",
    "prediction_xgb_optuna = xgb_optuna.predict(X_test)\n",
    "joblib.dump(xgb_optuna, 'xgb_optuna.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e50c9c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial value: 0.39861111111111114\n",
      "Best params: {'n_estimators': 793, 'learning_rate': 0.0173479773032578, 'max_depth': 10, 'subsample': 0.9705738392968393, 'colsample_bytree': 0.9839003732751974, 'min_child_weight': 3, 'reg_alpha': 1.1352592533617638, 'reg_lambda': 8.635414808107326}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_optuna_reg.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter-tuning w/Optuna (Regressor)\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import torch\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        #'num_class': 5,\n",
    "        'tree_method': 'hist', # Faster training\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu', # Use GPU if available\n",
    "        # Tuning parameters\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000), # More trees, but early stopping handles it\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "    }\n",
    "\n",
    "    # Split for early stopping (Optuna needs a validation set)\n",
    "    # Using specific validation set\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, \n",
    "                                                #stratify=y_train\n",
    "                                                )\n",
    "\n",
    "    # Choose regressor if trying to use with optimied rounder\n",
    "    model = xgb.XGBRegressor(**params, early_stopping_rounds=50)\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # FIXED: Round continuous predictions to integers for Kappa calculation\n",
    "    preds = model.predict(X_val)\n",
    "    preds_rounded = np.rint(preds).astype(int).clip(0, 4) \n",
    "    kappa = cohen_kappa_score(y_val, preds_rounded, weights='quadratic')\n",
    "    return kappa\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50) # Run 50 smart trials\n",
    "\n",
    "print(f\"Best trial value: {study.best_value}\")\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "\n",
    "# Use best params\n",
    "best_params = study.best_params\n",
    "# Add fixed params back\n",
    "best_params['objective'] = 'reg:squarederror'\n",
    "\n",
    "xgb_optuna_reg = xgb.XGBRegressor(**best_params)\n",
    "xgb_optuna_reg.fit(X_train, y_train) \n",
    "prediction_reg_raw = xgb_optuna_reg.predict(X_test)\n",
    "prediction_xgb_reg = np.rint(prediction_reg_raw).astype(int).clip(0, 4)\n",
    "joblib.dump(xgb_optuna_reg, 'xgb_optuna_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc10179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: [0.52654719 1.69745624 2.48101806 3.3206787 ]\n",
      "[4. 2. 4. ... 2. 4. 3.]\n",
      "Optimized Kappa: 0.8769456623006578\n",
      "Original Kappa is 0.395690369237631\n"
     ]
    }
   ],
   "source": [
    "# This works!\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from functools import partial\n",
    "xgb_testing = joblib.load(\"../models/v1_stratify/xgb_stratify_optuna.pkl\")\n",
    "class OptimizedRounder:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        # Bins predictions based on the coefficients (thresholds)\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll # Minimize the negative kappa (maximize kappa)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        # Start with standard rounding thresholds\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "# 1. Get Probability Predictions from your tuned model\n",
    "probs_train = xgb_testing.predict_proba(X_train)\n",
    "probs_test = xgb_testing.predict_proba(X_test)\n",
    "\n",
    "# 2. Convert to Expected Value (continuous calculation: sum(prob * class_label))\n",
    "# This turns probabilities into a single number (e.g., 2.34)\n",
    "train_preds_continuous = np.sum(probs_train * np.arange(5), axis=1)\n",
    "test_preds_continuous = np.sum(probs_test * np.arange(5), axis=1)\n",
    "\n",
    "# 3. Fit the Optimized Rounder on Training Data\n",
    "optR = OptimizedRounder()\n",
    "optR.fit(train_preds_continuous, y_train)\n",
    "\n",
    "# View the learned thresholds (e.g., instead of 0.5, it might be 0.6)\n",
    "print(f\"Optimized Thresholds: {optR.coef_['x']}\")\n",
    "\n",
    "# 4. Predict on Test Data using the new thresholds\n",
    "final_predictions = optR.predict(test_preds_continuous, optR.coef_['x'])\n",
    "print (final_predictions)\n",
    "# 5. Evaluate\n",
    "print(\"Optimized Kappa:\", cohen_kappa_score(y_test, final_predictions, weights='quadratic'))\n",
    "print (f\"Original Kappa is {cohen_kappa_score(y_test, prediction_xgb_optuna, weights='quadratic')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3851798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal thresholds: [1.073699018565312, 1.982124080826686, 2.4752246488824428, 3.098275842155716]\n",
      "Optimal Quadratic kappa: 0.4726\n",
      "Original Quadratic kappa: 0.3957\n"
     ]
    }
   ],
   "source": [
    "# This also works\n",
    "from oprounder import OptimizedRounder\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "\n",
    "# Get Probability Predictions from your tuned model\n",
    "probs_train_clf = xgb_optuna.predict_proba(X_train)\n",
    "probs_test_clf = xgb_optuna.predict_proba(X_test)\n",
    "\n",
    "# Convert to Expected Value (continuous calculation: sum(prob * class_label))\n",
    "# This turns probabilities into a single number (e.g., 2.34)\n",
    "train_preds_continuous = np.sum(probs_train_clf * np.arange(5), axis=1)\n",
    "test_preds_continuous = np.sum(probs_test_clf * np.arange(5), axis=1)\n",
    "\n",
    "# Fit the Optimized Rounder on Training Data\n",
    "rounder = OptimizedRounder(n_classes=y_train.nunique(), n_trials=100)\n",
    "rounder.fit(train_preds_continuous, y_train) #TODO: Change this appro.\n",
    "\n",
    "\n",
    "# View the learned thresholds\n",
    "print(f'Optimal thresholds: {rounder.thresholds}')\n",
    "\n",
    "# Predict on Test Data using the new thresholds\n",
    "prediction_clf_optimized = rounder.predict(test_preds_continuous) # use the new threshold to pick label\n",
    "\n",
    "# Compare how the new threshold improve kappa\n",
    "kappa = cohen_kappa_score(y_test, prediction_clf_optimized, weights='quadratic')\n",
    "print(f'Optimal Quadratic kappa: {kappa:.4f}')\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, prediction_xgb_optuna, weights='quadratic')\n",
    "print(f'Original Quadratic kappa: {kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d7a7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal thresholds: [1.1327455285952075, 1.858993744899881, 2.6334310043069786, 3.0607235624869666]\n",
      "Optimal Quadratic kappa: 0.4422\n",
      "Original Quadratic kappa: 0.3707\n"
     ]
    }
   ],
   "source": [
    "# Regressor version \n",
    "from oprounder import OptimizedRounder\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "pred_train_reg = xgb_optuna_reg.predict(X_train)\n",
    "pred_test_reg = xgb_optuna_reg.predict(X_test)\n",
    "\n",
    "# Fit the Optimized Rounder on Training Data\n",
    "rounder = OptimizedRounder(n_classes=y_train.nunique(), n_trials=100)\n",
    "rounder.fit(pred_train_reg, y_train) #TODO: Change this appro.\n",
    "\n",
    "\n",
    "# View the learned thresholds\n",
    "print(f'Optimal thresholds: {rounder.thresholds}')\n",
    "\n",
    "# Predict on Test Data using the new thresholds\n",
    "prediction_reg_optimized = rounder.predict(test_preds_continuous) # use the new threshold to pick label\n",
    "\n",
    "# Compare how the new threshold improve kappa\n",
    "kappa = cohen_kappa_score(y_test, prediction_reg_optimized, weights='quadratic')\n",
    "print(f'Optimal Quadratic kappa: {kappa:.4f}')\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, prediction_xgb_reg, weights='quadratic')\n",
    "print(f'Original Quadratic kappa: {kappa:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c887d",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DummyClassifier\n",
      "Kappa Score: 0.0000\n",
      "Accuracy Score: 0.2778\n",
      "Unique predictions by Dummy Classifier: [4]\n",
      "\n",
      "- Basic XGBoost Classifier\n",
      "Model: XGBClassifier\n",
      "Kappa Score: 0.3399\n",
      "Accuracy Score: 0.4258\n",
      "\n",
      "- Tuned XGBoost Classifier (w/Optuna) - \n",
      "Model: XGBClassifier\n",
      "Kappa Score: 0.3957\n",
      "Accuracy Score: 0.4542\n",
      "\n",
      "- Tuned XGBoost Regressor - \n",
      "Model: XGBRegressor\n",
      "Kappa Score: 0.3707\n",
      "Accuracy Score: 0.3278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, model_prediction):\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Kappa Score: {cohen_kappa_score(model_prediction, y_test, weights='quadratic'):.4f}\")\n",
    "    print(f\"Accuracy Score: {accuracy_score(model_prediction, y_test):.4f}\")\n",
    "    \n",
    "\n",
    "evaluate_model(dummy_clf, prediction_dummy) # Kappa should be 0 bcuz it's random\n",
    "print(f\"Unique predictions by Dummy Classifier: {np.unique(prediction_dummy)}\")\n",
    "print (\"\")\n",
    "\n",
    "print (\"- Basic XGBoost Classifier\")\n",
    "evaluate_model(xgb_clf, prediction_xgb)\n",
    "print (\"\")\n",
    "#print (\"- Tuned XGBoost Classifier- \")\n",
    "#evaluate_model(xgb_bestmodel, prediction_xgb_best)\n",
    "\n",
    "print (\"- Tuned XGBoost Classifier (w/Optuna) - \")\n",
    "evaluate_model(xgb_optuna, prediction_xgb_optuna)\n",
    "print (\"\")\n",
    "\n",
    "print (\"- Tuned XGBoost Regressor (Standard Rounding) - \")\n",
    "evaluate_model(xgb_optuna_reg, prediction_xgb_reg)\n",
    "print (\"\")\n",
    "\n",
    "print (\"- Tuned XGBoost Regressor (Optimized Rounding) - \")\n",
    "evaluate_model(xgb_optuna_reg, prediction_xgb_reg)\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56851b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance: which factors benefit the prediction the most (extracted from XGBoost)\n",
    "# ensure usage of original feature names not just np array indices\n",
    "xgb_clf.get_booster().feature_names = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "xgb.plot_importance(xgb_clf, max_num_features=10, height=0.5, importance_type=\"gain\", values_format = \"{v:.2f}\") # Weight  tree, Gain \n",
    "plt.title(\"Feature Importance (Gain)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
